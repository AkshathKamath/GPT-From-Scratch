{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "38638d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "090b4b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized sentence: ['The', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog']\n",
      "Number of tokens: 9\n"
     ]
    }
   ],
   "source": [
    "sentence = \"The quick brown fox jumps over the lazy dog\"\n",
    "\n",
    "## Simple tokenization by splitting on spaces, ideally more complex tokenization would be used like BPE or WordPiece\n",
    "sentence = sentence.split()\n",
    "n = len(sentence)\n",
    "\n",
    "print(f\"Tokenized sentence: {sentence}\")\n",
    "print(f\"Number of tokens: {len(sentence)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc915b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word embeddings (4-dimensional):\n",
      "  The : tensor([1.0000, 0.5000, 0.2000, 0.8000])\n",
      "  quick: tensor([0.3000, 1.0000, 0.7000, 0.1000])\n",
      "  brown: tensor([0.6000, 0.2000, 1.0000, 0.4000])\n",
      "  fox : tensor([0.9000, 0.8000, 0.3000, 1.0000])\n",
      "  jumps: tensor([0.4000, 0.6000, 0.8000, 0.2000])\n",
      "  over: tensor([0.7000, 0.3000, 0.5000, 0.9000])\n",
      "  the : tensor([1.0000, 0.5000, 0.2000, 0.8000])\n",
      "  lazy: tensor([0.2000, 0.9000, 0.4000, 0.6000])\n",
      "  dog : tensor([0.8000, 0.4000, 0.9000, 0.3000])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Sample word embeddings, ideally these would be learned in the language modelling process or loaded from a pre-trained model like GloVe or Word2Vec\n",
    "\n",
    "# Shape of embeddings: (n, d) where n is number of tokens and d is embedding dimension\n",
    "embeddings = torch.tensor([\n",
    "        [1.0, 0.5, 0.2, 0.8], \n",
    "        [0.3, 1.0, 0.7, 0.1],  \n",
    "        [0.6, 0.2, 1.0, 0.4],  \n",
    "        [0.9, 0.8, 0.3, 1.0],  \n",
    "        [0.4, 0.6, 0.8, 0.2],  \n",
    "        [0.7, 0.3, 0.5, 0.9],  \n",
    "        [1.0, 0.5, 0.2, 0.8],  \n",
    "        [0.2, 0.9, 0.4, 0.6],  \n",
    "        [0.8, 0.4, 0.9, 0.3]  \n",
    "    ])\n",
    "\n",
    "print(\"Word embeddings (4-dimensional):\")\n",
    "for i, word in enumerate(sentence):\n",
    "    print(f\"  {word:4}: {embeddings[i]}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a7d7e2aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positional embeddings (Same dimesnions as word embeddings):\n",
      "  Pos 0 (The): tensor([0., 1., 0., 1.])\n",
      "  Pos 1 (quick): tensor([0.1000, 0.9000, 0.1000, 0.9000])\n",
      "  Pos 2 (brown): tensor([0.2000, 0.8000, 0.2000, 0.8000])\n",
      "  Pos 3 (fox): tensor([0.3000, 0.7000, 0.3000, 0.7000])\n",
      "  Pos 4 (jumps): tensor([0.4000, 0.6000, 0.4000, 0.6000])\n",
      "  Pos 5 (over): tensor([0.5000, 0.5000, 0.5000, 0.5000])\n",
      "  Pos 6 (the): tensor([0.6000, 0.4000, 0.6000, 0.4000])\n",
      "  Pos 7 (lazy): tensor([0.7000, 0.3000, 0.7000, 0.3000])\n",
      "  Pos 8 (dog): tensor([0.8000, 0.2000, 0.8000, 0.2000])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Sample positional encodings, typically these would be generated using math functions or learned during training or RoPE\n",
    "\n",
    "positional_embeddings = torch.tensor([\n",
    "    [0.0, 1.0, 0.0, 1.0],  \n",
    "    [0.1, 0.9, 0.1, 0.9],  \n",
    "    [0.2, 0.8, 0.2, 0.8],  \n",
    "    [0.3, 0.7, 0.3, 0.7],  \n",
    "    [0.4, 0.6, 0.4, 0.6],  \n",
    "    [0.5, 0.5, 0.5, 0.5],  \n",
    "    [0.6, 0.4, 0.6, 0.4],  \n",
    "    [0.7, 0.3, 0.7, 0.3],  \n",
    "    [0.8, 0.2, 0.8, 0.2]   \n",
    "])\n",
    "\n",
    "print(\"Positional embeddings (Same dimesnions as word embeddings):\")\n",
    "for i, word in enumerate(sentence):\n",
    "    print(f\"  Pos {i} ({word}): {positional_embeddings[i]}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d742a8d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input embeddings (word + positional):\n",
      "  The : tensor([1.0000, 1.5000, 0.2000, 1.8000])\n",
      "  quick: tensor([0.4000, 1.9000, 0.8000, 1.0000])\n",
      "  brown: tensor([0.8000, 1.0000, 1.2000, 1.2000])\n",
      "  fox : tensor([1.2000, 1.5000, 0.6000, 1.7000])\n",
      "  jumps: tensor([0.8000, 1.2000, 1.2000, 0.8000])\n",
      "  over: tensor([1.2000, 0.8000, 1.0000, 1.4000])\n",
      "  the : tensor([1.6000, 0.9000, 0.8000, 1.2000])\n",
      "  lazy: tensor([0.9000, 1.2000, 1.1000, 0.9000])\n",
      "  dog : tensor([1.6000, 0.6000, 1.7000, 0.5000])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## The final input to the Attention block is the sum of the word embeddings and positional encodings\n",
    "\n",
    "input_embeddings = embeddings + positional_embeddings\n",
    "\n",
    "print(\"Input embeddings (word + positional):\")\n",
    "for i, word in enumerate(sentence):\n",
    "    print(f\"  {word:4}: {input_embeddings[i]}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7fbc9026",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 4      # embedding dimension of the tokens\n",
    "num_heads = 2    # number of attention heads\n",
    "d_k = d_model // num_heads # Dimension of the Q, K and V matrices for each head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a2cfef11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W_q (Query weights) shape: torch.Size([2, 4, 2])\n",
      "tensor([[[ 0.5781,  0.4462],\n",
      "         [ 0.2702, -0.6317],\n",
      "         [ 0.2035, -0.3704],\n",
      "         [-0.0129, -0.4814]],\n",
      "\n",
      "        [[-0.2256,  0.4946],\n",
      "         [-0.1177, -0.4211],\n",
      "         [-0.2184, -0.1678],\n",
      "         [-0.2307,  0.2287]]])\n",
      "\n",
      "W_k (Key weights) shape: torch.Size([2, 4, 2])\n",
      "tensor([[[ 0.4927, -0.0479],\n",
      "         [-0.1492,  0.1319],\n",
      "         [-0.2274,  0.3235],\n",
      "         [ 0.2402,  0.5042]],\n",
      "\n",
      "        [[ 0.3837,  0.3889],\n",
      "         [ 0.1831,  0.4004],\n",
      "         [-0.0695,  0.0125],\n",
      "         [-0.0755,  0.2580]]])\n",
      "\n",
      "W_v (Value weights) shape: torch.Size([2, 4, 2])\n",
      "tensor([[[-0.4154, -0.2614],\n",
      "         [-0.0670,  0.5152],\n",
      "         [ 0.0957, -0.1274],\n",
      "         [ 0.0917, -0.2324]],\n",
      "\n",
      "        [[-0.4673,  0.2987],\n",
      "         [-0.2639, -0.1803],\n",
      "         [-0.3822,  0.6368],\n",
      "         [-0.3704, -0.1464]]])\n",
      "\n",
      "W_o (Output projection weights) shape: torch.Size([4, 4])\n",
      "tensor([[-0.2741, -0.1974,  0.0234,  0.1577],\n",
      "        [-0.1464,  0.3574, -0.2442, -0.2208],\n",
      "        [-0.4210,  0.0108, -0.0190,  0.2027],\n",
      "        [-0.0293,  0.5534, -0.3554,  0.4151]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "## Shape of the weights is (num_heads, d_model, d_k) for Q, K, V and (d_model, d_model) for output projection\n",
    "W_q = torch.randn(num_heads, d_model, d_k, dtype=torch.float32) * 0.3  # Query wieghts\n",
    "W_k = torch.randn(num_heads, d_model, d_k, dtype=torch.float32) * 0.3  # Key weights\n",
    "W_v = torch.randn(num_heads, d_model, d_k, dtype=torch.float32) * 0.3  # Value weights\n",
    "W_o = torch.randn(d_model, d_model) * 0.3 # Output projection weights. This is applied after concatenating the heads so that the head outputs can interact information with each other.\n",
    "\n",
    "print(f\"W_q (Query weights) shape: {W_q.shape}\")\n",
    "print(W_q)\n",
    "print(f\"\\nW_k (Key weights) shape: {W_k.shape}\")\n",
    "print(W_k)\n",
    "print(f\"\\nW_v (Value weights) shape: {W_v.shape}\")\n",
    "print(W_v)\n",
    "print()\n",
    "\n",
    "print(f\"W_o (Output projection weights) shape: {W_o.shape}\")\n",
    "print(W_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "94ac313b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## To concatenate the outputs of each of the self attention heads, we will store them in this list. This will be of shape (num_heads, n, d_k)\n",
    "head_outputs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8c0aea3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== HEAD 1 ===\n",
      "Head 1 - Computing Q, K, V using weight matrices:\n",
      "  Q_h = input_embeddings @ W_q[0]  ->  shape: torch.Size([9, 2])\n",
      "  K_h = input_embeddings @ W_k[0]  ->  shape: torch.Size([9, 2])\n",
      "  V_h = input_embeddings @ W_v[0]  ->  shape: torch.Size([9, 2])\n",
      "\n",
      "=== HEAD 2 ===\n",
      "Head 2 - Computing Q, K, V using weight matrices:\n",
      "  Q_h = input_embeddings @ W_q[1]  ->  shape: torch.Size([9, 2])\n",
      "  K_h = input_embeddings @ W_k[1]  ->  shape: torch.Size([9, 2])\n",
      "  V_h = input_embeddings @ W_v[1]  ->  shape: torch.Size([9, 2])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for head in range(num_heads):\n",
    "    print(f\"=== HEAD {head + 1} ===\")\n",
    "    \n",
    "    # Compute Q, K, V for this specific head only\n",
    "    Q_h = torch.matmul(input_embeddings, W_q[head])  # (n, d_k)\n",
    "    K_h = torch.matmul(input_embeddings, W_k[head])  # (n, d_k)\n",
    "    V_h = torch.matmul(input_embeddings, W_v[head])  # (n, d_k)\n",
    "    \n",
    "    print(f\"Head {head + 1} - Computing Q, K, V using weight matrices:\")\n",
    "    print(f\"  Q_h = input_embeddings @ W_q[{head}]  ->  shape: {Q_h.shape}\")\n",
    "    print(f\"  K_h = input_embeddings @ W_k[{head}]  ->  shape: {K_h.shape}\")\n",
    "    print(f\"  V_h = input_embeddings @ W_v[{head}]  ->  shape: {V_h.shape}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e16e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== HEAD 1 ===\n",
      "Head 1 - Attention scores (Q_h @ K_h.T) scaled by sqrt(d_k): torch.Size([9, 9])\n",
      "Head 1 - Attention weights after softmax: torch.Size([9, 9])\n",
      "Head 1 - Output (attention_weights_h @ V_h): torch.Size([9, 2])\n",
      "\n",
      "=== HEAD 2 ===\n",
      "Head 2 - Attention scores (Q_h @ K_h.T) scaled by sqrt(d_k): torch.Size([9, 9])\n",
      "Head 2 - Attention weights after softmax: torch.Size([9, 9])\n",
      "Head 2 - Output (attention_weights_h @ V_h): torch.Size([9, 2])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for head in range(num_heads):\n",
    "    print(f\"=== HEAD {head + 1} ===\")\n",
    "\n",
    "    Q_h = torch.matmul(input_embeddings, W_q[head])  \n",
    "    K_h = torch.matmul(input_embeddings, W_k[head]) \n",
    "    V_h = torch.matmul(input_embeddings, W_v[head]) \n",
    "\n",
    "    attention_scores_h = torch.matmul(Q_h, K_h.T) # (n, n)\n",
    "    attention_scores_h /= torch.sqrt(torch.tensor(d_k, dtype=torch.float32)) # Scale the scores\n",
    "    print(f\"Head {head + 1} - Attention scores (Q_h @ K_h.T) scaled by sqrt(d_k): {attention_scores_h.shape}\")\n",
    "\n",
    "    attention_weights_h = F.softmax(attention_scores_h, dim = -1) # (n, n)\n",
    "    print(f\"Head {head + 1} - Attention weights after softmax: {attention_weights_h.shape}\")\n",
    "\n",
    "    output_h = torch.matmul(attention_weights_h, V_h) # (n, d_k)\n",
    "    print(f\"Head {head + 1} - Output (attention_weights_h @ V_h): {output_h.shape}\")\n",
    "\n",
    "    ## Will have shape (n_heads, n, d_k) after appending all head outputs\n",
    "    head_outputs.append(output_h)\n",
    "    print()   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "182efb03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenated output from all heads: torch.Size([9, 4])\n"
     ]
    }
   ],
   "source": [
    "## Concatenate the output of each head along the last dimension i.e. over the d_k dimension (rows). num_heads * d_k = d_model\n",
    "\n",
    "concatenated_output = torch.cat(head_outputs, dim=1) # (n, d_model)\n",
    "print(f\"Concatenated output from all heads: {concatenated_output.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c4a3ce0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final output after output projection (concatenated_output @ W_o): torch.Size([9, 4])\n"
     ]
    }
   ],
   "source": [
    "final_output = torch.matmul(concatenated_output, W_o) # (n, d_model)\n",
    "print(f\"Final output after output projection (concatenated_output @ W_o): {final_output.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "235f1508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.7657,  0.3064, -0.1404, -0.1354],\n",
      "        [ 0.7626,  0.3212, -0.1500, -0.1233],\n",
      "        [ 0.7642,  0.3108, -0.1435, -0.1325],\n",
      "        [ 0.7672,  0.3047, -0.1389, -0.1348],\n",
      "        [ 0.7640,  0.3141, -0.1455, -0.1295],\n",
      "        [ 0.7662,  0.3032, -0.1384, -0.1383],\n",
      "        [ 0.7682,  0.2995, -0.1357, -0.1403],\n",
      "        [ 0.7646,  0.3121, -0.1442, -0.1309],\n",
      "        [ 0.7678,  0.3030, -0.1378, -0.1371]])\n"
     ]
    }
   ],
   "source": [
    "print(final_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
