{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "709e8d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8f9ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Implemented using the Attention notebooks in the Attention directory\n",
    "\n",
    "def selfAttention(input_embeddings, W_q, W_k, W_v, W_o):\n",
    "    n = input_embeddings.shape[0]\n",
    "    d_model = input_embeddings.shape[1]\n",
    "    d_k = W_q.shape[1]\n",
    "\n",
    "    Q = torch.matmul(input_embeddings, W_q)\n",
    "    K = torch.matmul(input_embeddings, W_k)\n",
    "    V = torch.matmul(input_embeddings, W_v)\n",
    "\n",
    "    mask  = torch.tril(torch.ones(n, n))\n",
    "\n",
    "    attention_scores = torch.matmul(Q, K.T)\n",
    "    masked_attention_scores = attention_scores.masked_fill(mask == 0, float('-inf'))\n",
    "    masked_attention_scores /= torch.sqrt(torch.tensor(d_k, dtype=torch.float32))\n",
    "\n",
    "    attention_weights = F.softmax(masked_attention_scores, dim=-1)\n",
    "    output = torch.matmul(attention_weights, V)\n",
    "    final_output = torch.matmul(output, W_o)\n",
    "\n",
    "    return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3b34e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized sentence: ['The', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog']\n",
      "Number of tokens: 9\n"
     ]
    }
   ],
   "source": [
    "sentence = \"The quick brown fox jumps over the lazy dog\"\n",
    "\n",
    "## Simple tokenization by splitting on spaces, ideally more complex tokenization would be used like BPE or WordPiece\n",
    "sentence = sentence.split()\n",
    "n = len(sentence)\n",
    "\n",
    "print(f\"Tokenized sentence: {sentence}\")\n",
    "print(f\"Number of tokens: {len(sentence)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "402198da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word embeddings (4-dimensional):\n",
      "  The : tensor([1.0000, 0.5000, 0.2000, 0.8000])\n",
      "  quick: tensor([0.3000, 1.0000, 0.7000, 0.1000])\n",
      "  brown: tensor([0.6000, 0.2000, 1.0000, 0.4000])\n",
      "  fox : tensor([0.9000, 0.8000, 0.3000, 1.0000])\n",
      "  jumps: tensor([0.4000, 0.6000, 0.8000, 0.2000])\n",
      "  over: tensor([0.7000, 0.3000, 0.5000, 0.9000])\n",
      "  the : tensor([1.0000, 0.5000, 0.2000, 0.8000])\n",
      "  lazy: tensor([0.2000, 0.9000, 0.4000, 0.6000])\n",
      "  dog : tensor([0.8000, 0.4000, 0.9000, 0.3000])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Sample word embeddings, ideally these would be learned in the language modelling process or loaded from a pre-trained model like GloVe or Word2Vec\n",
    "\n",
    "# Shape of embeddings: (n, d) where n is number of tokens and d is embedding dimension\n",
    "embeddings = torch.tensor([\n",
    "        [1.0, 0.5, 0.2, 0.8], \n",
    "        [0.3, 1.0, 0.7, 0.1],  \n",
    "        [0.6, 0.2, 1.0, 0.4],  \n",
    "        [0.9, 0.8, 0.3, 1.0],  \n",
    "        [0.4, 0.6, 0.8, 0.2],  \n",
    "        [0.7, 0.3, 0.5, 0.9],  \n",
    "        [1.0, 0.5, 0.2, 0.8],  \n",
    "        [0.2, 0.9, 0.4, 0.6],  \n",
    "        [0.8, 0.4, 0.9, 0.3]  \n",
    "    ])\n",
    "\n",
    "print(\"Word embeddings (4-dimensional):\")\n",
    "for i, word in enumerate(sentence):\n",
    "    print(f\"  {word:4}: {embeddings[i]}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b254303d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positional embeddings (Same dimesnions as word embeddings):\n",
      "  Pos 0 (The): tensor([0., 1., 0., 1.])\n",
      "  Pos 1 (quick): tensor([0.1000, 0.9000, 0.1000, 0.9000])\n",
      "  Pos 2 (brown): tensor([0.2000, 0.8000, 0.2000, 0.8000])\n",
      "  Pos 3 (fox): tensor([0.3000, 0.7000, 0.3000, 0.7000])\n",
      "  Pos 4 (jumps): tensor([0.4000, 0.6000, 0.4000, 0.6000])\n",
      "  Pos 5 (over): tensor([0.5000, 0.5000, 0.5000, 0.5000])\n",
      "  Pos 6 (the): tensor([0.6000, 0.4000, 0.6000, 0.4000])\n",
      "  Pos 7 (lazy): tensor([0.7000, 0.3000, 0.7000, 0.3000])\n",
      "  Pos 8 (dog): tensor([0.8000, 0.2000, 0.8000, 0.2000])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Sample positional encodings, typically these would be generated using math functions or learned during training or RoPE\n",
    "\n",
    "positional_embeddings = torch.tensor([\n",
    "    [0.0, 1.0, 0.0, 1.0],  \n",
    "    [0.1, 0.9, 0.1, 0.9],  \n",
    "    [0.2, 0.8, 0.2, 0.8],  \n",
    "    [0.3, 0.7, 0.3, 0.7],  \n",
    "    [0.4, 0.6, 0.4, 0.6],  \n",
    "    [0.5, 0.5, 0.5, 0.5],  \n",
    "    [0.6, 0.4, 0.6, 0.4],  \n",
    "    [0.7, 0.3, 0.7, 0.3],  \n",
    "    [0.8, 0.2, 0.8, 0.2]   \n",
    "])\n",
    "\n",
    "print(\"Positional embeddings (Same dimesnions as word embeddings):\")\n",
    "for i, word in enumerate(sentence):\n",
    "    print(f\"  Pos {i} ({word}): {positional_embeddings[i]}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0066e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input embeddings (word + positional):\n",
      "  The : tensor([1.0000, 1.5000, 0.2000, 1.8000])\n",
      "  quick: tensor([0.4000, 1.9000, 0.8000, 1.0000])\n",
      "  brown: tensor([0.8000, 1.0000, 1.2000, 1.2000])\n",
      "  fox : tensor([1.2000, 1.5000, 0.6000, 1.7000])\n",
      "  jumps: tensor([0.8000, 1.2000, 1.2000, 0.8000])\n",
      "  over: tensor([1.2000, 0.8000, 1.0000, 1.4000])\n",
      "  the : tensor([1.6000, 0.9000, 0.8000, 1.2000])\n",
      "  lazy: tensor([0.9000, 1.2000, 1.1000, 0.9000])\n",
      "  dog : tensor([1.6000, 0.6000, 1.7000, 0.5000])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## The final input to the Attention block is the sum of the word embeddings and positional encodings\n",
    "\n",
    "input_embeddings = embeddings + positional_embeddings\n",
    "\n",
    "print(\"Input embeddings (word + positional):\")\n",
    "for i, word in enumerate(sentence):\n",
    "    print(f\"  {word:4}: {input_embeddings[i]}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a30e7b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = input_embeddings.shape[1]  # Embedding dimension\n",
    "d_k = 3 # Dimension of keys and queries (generally kept smaller to make Q, K and V matrices low rank for efficiency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6bf43ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W_q (Query weights) shape: torch.Size([4, 3])\n",
      "tensor([[ 0.1010,  0.0386,  0.0703],\n",
      "        [ 0.0691, -0.3369, -0.0559],\n",
      "        [ 0.6625, -0.1914,  0.1385],\n",
      "        [ 0.0802,  0.1605,  0.2428]])\n",
      "\n",
      "W_k (Key weights) shape: torch.Size([4, 3])\n",
      "tensor([[ 0.3331, -0.5069, -0.2967],\n",
      "        [ 0.2874,  0.3966,  0.2452],\n",
      "        [-0.2298, -0.2252,  0.4058],\n",
      "        [ 0.2059, -0.0983,  0.2385]])\n",
      "\n",
      "W_v (Value weights) shape: torch.Size([4, 3])\n",
      "tensor([[ 0.0845,  0.0168,  0.1568],\n",
      "        [-0.0715, -0.0150,  0.1579],\n",
      "        [-0.0025,  0.2187,  0.0399],\n",
      "        [ 0.2592, -0.3047, -0.2666]])\n",
      "\n",
      "W_o (Output projection weights) shape: torch.Size([3, 4])\n",
      "tensor([[ 0.0449, -0.0627, -0.1161,  0.2974],\n",
      "        [ 0.1404, -0.0615, -0.2223,  0.1086],\n",
      "        [ 0.5760, -0.0676, -0.1025,  0.0912]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)  # For reproducible results\n",
    "\n",
    "## Shape of the Q, K and V matrices is d x d_k and for the output projection matrix is d_k x d to project the attention output back to d dimensions\n",
    "W_q = torch.randn(d_model, d_k, dtype=torch.float32) * 0.3  \n",
    "W_k = torch.randn(d_model, d_k, dtype=torch.float32) * 0.3  \n",
    "W_v = torch.randn(d_model, d_k, dtype=torch.float32) * 0.3  \n",
    "W_o = torch.randn(d_k, d_model, dtype=torch.float32) * 0.3 \n",
    "\n",
    "print(f\"W_q (Query weights) shape: {W_q.shape}\")\n",
    "print(W_q)\n",
    "print(f\"\\nW_k (Key weights) shape: {W_k.shape}\")\n",
    "print(W_k)\n",
    "print(f\"\\nW_v (Value weights) shape: {W_v.shape}\")\n",
    "print(W_v)\n",
    "print()\n",
    "\n",
    "print(f\"W_o (Output projection weights) shape: {W_o.shape}\")\n",
    "print(W_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b45bd40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Attention output shape: torch.Size([9, 4])\n",
      "tensor([[-0.0968,  0.0089,  0.0700,  0.0693],\n",
      "        [-0.0290,  0.0011,  0.0407,  0.0572],\n",
      "        [-0.0174, -0.0035,  0.0238,  0.0640],\n",
      "        [-0.0211, -0.0036,  0.0262,  0.0700],\n",
      "        [-0.0030, -0.0066,  0.0158,  0.0706],\n",
      "        [-0.0044, -0.0076,  0.0127,  0.0743],\n",
      "        [ 0.0043, -0.0094,  0.0083,  0.0785],\n",
      "        [ 0.0124, -0.0108,  0.0039,  0.0788],\n",
      "        [ 0.0287, -0.0139, -0.0053,  0.0823]])\n"
     ]
    }
   ],
   "source": [
    "attention_output = selfAttention(input_embeddings, W_q, W_k, W_v, W_o)\n",
    "\n",
    "print(\"\\nAttention output shape:\", attention_output.shape)\n",
    "print(attention_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92c485ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Residual output shape: torch.Size([9, 4])\n",
      "tensor([[0.9032, 1.5089, 0.2700, 1.8693],\n",
      "        [0.3710, 1.9011, 0.8407, 1.0572],\n",
      "        [0.7826, 0.9965, 1.2238, 1.2640],\n",
      "        [1.1789, 1.4964, 0.6262, 1.7700],\n",
      "        [0.7970, 1.1934, 1.2158, 0.8706],\n",
      "        [1.1956, 0.7924, 1.0127, 1.4743],\n",
      "        [1.6043, 0.8906, 0.8083, 1.2785],\n",
      "        [0.9124, 1.1892, 1.1039, 0.9788],\n",
      "        [1.6287, 0.5861, 1.6947, 0.5823]])\n"
     ]
    }
   ],
   "source": [
    "## Adding residual connection where the input embeddings before the attention block are added to the attention output\n",
    "residual_output = attention_output + input_embeddings\n",
    "\n",
    "print(\"\\nResidual output shape:\", residual_output.shape)\n",
    "print(residual_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04dc474d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gamma (scaling factor) shape: torch.Size([4])\n",
      "tensor([1., 1., 1., 1.])\n",
      "\n",
      "Beta (shifting factor) shape: torch.Size([4])\n",
      "tensor([0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "## Learnable parameters for layer normalization, gamma is the scaling factor and beta is the shifting factor\n",
    "gamma = torch.ones(d_model) # Shape: (d,) for every embedding dimension\n",
    "beta = torch.zeros(d_model) # Shape: (d,) for every embedding dimension\n",
    "\n",
    "print(\"\\nGamma (scaling factor) shape:\", gamma.shape)\n",
    "print(gamma)\n",
    "print(\"\\nBeta (shifting factor) shape:\", beta.shape)\n",
    "print(beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c01b8516",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now applying layer normalization to the residual output (Post-LN). Recent approaches use Pre-LN for better training stability\n",
    "def layerNorm(residual_output, gamma, beta, eps = 1e-5,):\n",
    "    ## For evert token (row), we calculate the mean and variance across the embedding dimension\n",
    "    means = torch.mean(residual_output, dim=-1, keepdim=True) # Shape (n, 1)\n",
    "    print(f\"Means shape: {means.shape}\")\n",
    "    variances = torch.var(residual_output, dim=-1, keepdim=True, unbiased=False) # Shape (n, 1)\n",
    "    print(f\"Variances shape: {variances.shape}\")\n",
    "\n",
    "    ## Normalizing the residual output i.e. making it zero mean and unit variance\n",
    "    normalized = (residual_output - means) / torch.sqrt(variances + eps) # Shape (n, d)\n",
    "    print(f\"Normalized shape: {normalized.shape}\")\n",
    "\n",
    "    ln_output = normalized * gamma + beta # Shape (n, d) after broadcasting of gamma and beta. For each token (row), we scale and shift the normalized values by element-wise multiplication and addition of the corresponding gamma and beta values for that embedding dimension (column)\n",
    "    return ln_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba815424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Means shape: torch.Size([9, 1])\n",
      "Variances shape: torch.Size([9, 1])\n",
      "Normalized shape: torch.Size([9, 4])\n",
      "\n",
      "Final output shape: torch.Size([9, 4])\n",
      "tensor([[-0.3856,  0.6098, -1.4263,  1.2021],\n",
      "        [-1.2114,  1.5489, -0.3639,  0.0265],\n",
      "        [-1.4708, -0.3633,  0.8130,  1.0211],\n",
      "        [-0.2092,  0.5371, -1.5082,  1.1802],\n",
      "        [-1.1857,  0.9293,  1.0492, -0.7928],\n",
      "        [ 0.3073, -1.3051, -0.4240,  1.4219],\n",
      "        [ 1.4387, -0.7991, -1.0569,  0.4173],\n",
      "        [-1.2430,  1.3310,  0.5375, -0.6255],\n",
      "        [ 0.9378, -0.9955,  1.0603, -1.0026]])\n"
     ]
    }
   ],
   "source": [
    "final_output = layerNorm(residual_output, gamma, beta)\n",
    "\n",
    "print(\"\\nFinal output shape:\", final_output.shape)\n",
    "print(final_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
