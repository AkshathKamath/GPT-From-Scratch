Implementing core NLP and LLM topics from scratch in Pytorch.

- Attention
  - Self Attention
  - Multi Head Self Attention
  - Masked Self Attention
- Transformer
  - Complete Transformer block with residual connections, layer norm and feed forward networks
